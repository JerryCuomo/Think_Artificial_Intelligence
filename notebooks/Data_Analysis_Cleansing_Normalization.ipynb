{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a98f227",
   "metadata": {},
   "source": [
    "#### Data Analysis, Cleansing, and Normalization\n",
    "\n",
    "This notebook walks you through data processing steps using Python:\n",
    "\n",
    "- Analyze the dataset for key patterns.\n",
    "- Cleanse by identifying and handling missing or incorrect data.\n",
    "- Normalize by transforming data into a consistent format and replacing specific terms.\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d5b22",
   "metadata": {},
   "source": [
    "#### Step 1: Data Analysis\n",
    "\n",
    "In this step, we will load the dataset and perform some basic analysis to understand its structure and contents.\n",
    "\n",
    "1. Load the dataset.\n",
    "2. Display the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae2bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('https://jerrycuomo.github.io/Think_Artificial_Intelligence/datasets/climatebert-netzero-reduction-data.csv')\n",
    "\n",
    "#display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564943f5",
   "metadata": {},
   "source": [
    "#### Step 2: Data Cleansing\n",
    "\n",
    "Data cleansing involves identifying and correcting or removing incorrect, incomplete, or irrelevant data. In this step, we'll:\n",
    "1. Check for missing values.\n",
    "2. Remove rows with missing values in the 'text' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacaf5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Remove rows with missing values in the 'text' column\n",
    "data_cleaned = data.dropna(subset=['text'])\n",
    "\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2736e6f3",
   "metadata": {},
   "source": [
    "#### Step 3: Data Normalization\n",
    "\n",
    "Data normalization involves transforming data into a consistent format.\n",
    "1. Convert all text in the 'text' column to lowercase.\n",
    "2. Remove special characters and numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Convert all text to lowercase\n",
    "data_cleaned['text'] = data_cleaned['text'].str.lower()\n",
    "\n",
    "# Remove special characters and numbers\n",
    "data_cleaned['text'] = data_cleaned['text'].apply(lambda x: re.sub(r'[^a-z\\s]', '', x))\n",
    "\n",
    "data_cleaned.head() # Display the normalized dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f582aa66",
   "metadata": {},
   "source": [
    "#### Step 4: Counting Occurrences\n",
    "\n",
    "Now that we have cleaned and normalized the data, let's count the occurrences of the terms 'percent' and 'carbon dioxide' in the 'text' column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of 'percent' and 'carbon dioxide' in 'text' column\n",
    "count_percent = data_cleaned['text'].str.contains('percent').sum()\n",
    "count_carbon_dioxide = data_cleaned['text'].str.contains('carbon dioxide').sum()\n",
    "\n",
    "# Display the results\n",
    "print(f\"Occurrences of 'percent': {count_percent}\")\n",
    "print(f\"Occurrences of 'carbon dioxide': {count_carbon_dioxide}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd076008",
   "metadata": {},
   "source": [
    "#### Step 5: Replacing Terms and Sampling Entries\n",
    "\n",
    "Replace 'percent' with '%' and 'carbon dioxide' with 'CO2' in the 'text' column. Then, display a sample of entries that include these updated terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace occurrences of 'percent' with '%' and 'carbon dioxide' with 'CO2'\n",
    "data_cleaned['text'] = data_cleaned['text'].str.replace('percent', '%', case=False)\n",
    "data_cleaned['text'] = data_cleaned['text'].str.replace('carbon dioxide', 'CO2', case=False)\n",
    "\n",
    "# Increase display width for text column\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Display a sample of updated entries\n",
    "print(data_cleaned[data_cleaned['text'].str.contains('CO2|%', case=False)].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f377e",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "In this notebook, we learned how to:\n",
    "1. Analyze a dataset to understand its structure.\n",
    "2. Cleanse the data by handling missing values.\n",
    "3. Normalize the data for consistency.\n",
    "4. Count specific term occurrences\n",
    "\n",
    "These are all typical steps in data processing for preparing data for further analysis or machine learning.\n",
    "\n",
    "Great job!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
