# Source: "Think Artificial Intelligence" by Jerry Cuomo, 2024
# Purpose: Educational code examples from the book.
# Copyright Â© 2024 Jerry Cuomo. All rights reserved.
#
# This code was autogenerated by GPT-4, from the following prompt:
# Prompt: Analyze and plot the electric vehicle (EV) population data in 'datasets/electric_vehicle_population_data.csv' to identify patterns in VEHICLE RANGE and MODEL YEARS by clustering Battery Electric Vehicles (BEVs) and highlighting the cluster with the highest average ELECTRIC RANGE.
#
# About: This script performs a clustering analysis on electric vehicle data, focusing specifically on Battery Electric Vehicles (BEVs). 
# It uses the k-means algorithm to identify patterns in EV model years and electric ranges, highlighting the cluster with the highest average electric range. 
# The script utilizes Python's scikit-learn for clustering, pandas for data manipulation, and matplotlib for visualization.
#
# Setup: Python installed, with 'electric_vehicle_population_data.csv' in your directory. 
# Install scikit-learn, pandas, and matplotlib using 'pip install scikit-learn pandas matplotlib'.

import pandas as pd
import numpy as np  # Ensure numpy is imported
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('../datasets/electric_vehicle_population_data.csv')

# Ensure we are focusing only on BEVs
df = df[df['Electric Vehicle Type'] == 'Battery Electric Vehicle (BEV)']
df = df[df['Electric Range'] > 0]

# Number of clusters as an independent variable
num_clusters = 5  # Feel free to change this number and experiment

# Select features for clustering: Model Year and Electric Range
features = df[['Model Year', 'Electric Range']]

# Normalize the features
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

# Perform K-Means Clustering
kmeans = KMeans(n_clusters=num_clusters, random_state=42)
df['Cluster'] = kmeans.fit_predict(features_scaled)

# Identify the "winning" cluster with the highest average electric range
winning_cluster = df.groupby('Cluster')['Electric Range'].mean().idxmax()

# Colors for each cluster
colors = plt.cm.rainbow(np.linspace(0, 1, num_clusters))

# Plotting the clusters
plt.figure(figsize=(12, 8))
for cluster in range(num_clusters):
    cluster_data = df[df['Cluster'] == cluster]
    plt.scatter(cluster_data['Model Year'], cluster_data['Electric Range'], 
                color=colors[cluster], 
                label=f'Cluster {cluster}' if cluster == winning_cluster else None, 
                s=250 if cluster == winning_cluster else 150, 
                alpha=0.7)

plt.title('BEV Clusters by Model Year and Electric Range')
plt.xlabel('Model Year')
plt.ylabel('Electric Range')
plt.grid(True)

# Legend and text for the winning cluster
winning_legend = plt.legend(title="Winning Cluster", loc="upper left", fontsize='large', fancybox=True)
plt.setp(winning_legend.get_title(), fontsize='small', fontweight='bold')

# Sample vehicles from the winning cluster
winning_cars = df[df['Cluster'] == winning_cluster][['Model Year', 'Make', 'Model', 'Electric Range']].sample(10, random_state=42)
winning_text = '\n'.join([f"{int(row['Model Year'])} {row['Make']} {row['Model']} ({int(row['Electric Range'])} mi)" for index, row in winning_cars.iterrows()])
plt.annotate(winning_text, xy=(0.01, 0.9), xycoords='axes fraction', fontsize=10, horizontalalignment='left', verticalalignment='top')

plt.tight_layout()
plt.show()
